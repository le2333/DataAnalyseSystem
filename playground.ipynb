{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据导入与方法定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import panel as pn\n",
    "import hvplot.pandas\n",
    "\n",
    "# 初始化 Panel\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 指定目录路径\n",
    "dir_path = 'data/raw/sat3'\n",
    "\n",
    "# 获取目录中的文件列表\n",
    "file_list = os.listdir(dir_path)\n",
    "\n",
    "# 加载目录中的CSV文件\n",
    "csv_files = [f for f in file_list if f.endswith('.csv')]\n",
    "dataframes = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(dir_path, file)\n",
    "    dataframes[file] = pd.read_csv(file_path)\n",
    "    \n",
    "\n",
    "# 处理每个CSV数据框，设置时间索引\n",
    "for file, df in dataframes.items():\n",
    "    # 添加列名（因为原始数据无表头）\n",
    "    df.columns = ['timestamp', 'value']\n",
    "    \n",
    "    # 将时间戳列转换为datetime类型并设置为索引\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    # 删除重复值\n",
    "    df = df.loc[~df.index.duplicated(keep='first')]\n",
    "    \n",
    "    # 更新dataframes字典\n",
    "    dataframes[file] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原始数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 折线图\n",
    "# 创建文件选择器控件\n",
    "file_selector = pn.widgets.Select(\n",
    "    name='选择数据文件',\n",
    "    options=list(dataframes.keys()),\n",
    "    value=list(dataframes.keys())[0]\n",
    ")\n",
    "\n",
    "# 创建交互式函数\n",
    "@pn.depends(file=file_selector)\n",
    "def plot_data(file):\n",
    "    df = dataframes[file]\n",
    "    plot = df.hvplot.line(\n",
    "        downsample=True,\n",
    "        height=500,\n",
    "    )\n",
    "    tabulator = pn.widgets.Tabulator(df, buttons={'Print': \"<i class='fa fa-print'></i>\"})\n",
    "    return pn.Column(plot, tabulator)\n",
    "\n",
    "# 创建交互式面板\n",
    "dashboard = pn.Column(\n",
    "    pn.pane.Markdown(\"## 数据可视化\"),\n",
    "    pn.Column(\n",
    "        file_selector,\n",
    "        plot_data\n",
    "    )\n",
    ")\n",
    "\n",
    "# 显示面板\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs={}\n",
    "# 对每个dataframe绘制时间间隔分布图\n",
    "for file, df in dataframes.items():\n",
    "    # 计算时间间隔（毫秒）\n",
    "    time_diffs[file] = df.index.to_series().diff().dt.total_seconds().dropna().to_frame()\n",
    "    # print(time_diffs[file].min())\n",
    "# time_diffs\n",
    "\n",
    "# 创建文件选择器控件\n",
    "file_selector = pn.widgets.Select(\n",
    "    name='选择数据文件',\n",
    "    options=list(time_diffs.keys()),\n",
    "    value=list(time_diffs.keys())[0]\n",
    ")\n",
    "\n",
    "# 创建交互式函数\n",
    "@pn.depends(file=file_selector)\n",
    "def plot_data(file):\n",
    "    df = time_diffs[file]\n",
    "    plot = df.hvplot.hist(\n",
    "        bins=1000,\n",
    "        logy=True,\n",
    "        # yscale='log',\n",
    "        height=500,\n",
    "    )\n",
    "    df.index.name = None\n",
    "    df.reset_index(drop=False)\n",
    "    tabulator = pn.widgets.Tabulator(df)\n",
    "    return pn.Column(plot, tabulator)\n",
    "\n",
    "# 创建交互式面板\n",
    "dashboard = pn.Column(\n",
    "    pn.pane.Markdown(\"## 数据可视化\"),\n",
    "    pn.Column(\n",
    "        file_selector,\n",
    "        plot_data\n",
    "    )\n",
    ")\n",
    "\n",
    "# 显示面板\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "value_diffs={}\n",
    "# 对每个dataframe绘制数值间隔分布图\n",
    "for file, df in dataframes.items():\n",
    "    value_diffs[file] = df['value'].diff().dropna()\n",
    "\n",
    "# 创建文件选择器控件\n",
    "file_selector = pn.widgets.Select(\n",
    "    name='选择数据文件',\n",
    "    options=list(value_diffs.keys()),\n",
    "    value=list(value_diffs.keys())[0]\n",
    ")\n",
    "\n",
    "# 创建交互式函数\n",
    "@pn.depends(file=file_selector)\n",
    "def plot_data(file):\n",
    "    df = value_diffs[file]\n",
    "    plot = df.hvplot.hist(\n",
    "        bins=1000,\n",
    "        height=500,\n",
    "    )\n",
    "    tabulator = pn.widgets.Tabulator(df, buttons={'Print': \"<i class='fa fa-print'></i>\"})\n",
    "    return pn.Column(plot, tabulator)\n",
    "\n",
    "# 创建交互式面板\n",
    "dashboard = pn.Column(\n",
    "    pn.pane.Markdown(\"## 数据可视化\"),\n",
    "    pn.Column(\n",
    "        file_selector,\n",
    "        plot_data\n",
    "    )\n",
    ")\n",
    "\n",
    "# 显示面板\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 获取第一个DataFrame的副本\n",
    "first_file = list(dataframes.keys())[0]\n",
    "df_copy = dataframes[first_file].copy()\n",
    "\n",
    "# 提取value列数据作为观测值\n",
    "observations = df_copy['value'].values\n",
    "\n",
    "# 创建卡尔曼滤波器\n",
    "kf = KalmanFilter(\n",
    "    initial_state_mean=observations[0],\n",
    "    transition_matrices=[1],\n",
    "    observation_matrices=[1],\n",
    "    transition_covariance=0.01,\n",
    "    observation_covariance=1.0,\n",
    "    initial_state_covariance=1.0\n",
    ")\n",
    "\n",
    "# 应用卡尔曼滤波\n",
    "state_means, state_covs = kf.smooth(observations)\n",
    "\n",
    "# 将滤波结果添加到DataFrame中\n",
    "df_copy['kalman_filtered'] = state_means\n",
    "\n",
    "# 绘制原始数据和滤波后的数据\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_copy.index, df_copy['value'], 'b-', label='原始数据')\n",
    "plt.plot(df_copy.index, df_copy['kalman_filtered'], 'r-', label='卡尔曼滤波后数据')\n",
    "plt.title(f\"文件 {first_file} 的卡尔曼滤波结果\")\n",
    "plt.xlabel(\"时间\")\n",
    "plt.ylabel(\"数值\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"原始数据和滤波后数据的前5行：\")\n",
    "print(df_copy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 获取第一个数据框\n",
    "file = list(dataframes.keys())[-1]\n",
    "df_copy = dataframes[file].copy()\n",
    "# print(df_copy.head())\n",
    "\n",
    "# 应用Savitzky-Golay滤波\n",
    "# 参数: 窗口长度=51, 多项式阶数=3\n",
    "df_copy['sg_filtered'] = savgol_filter(df_copy['value'], window_length=20, polyorder=3)\n",
    "\n",
    "print(df_copy.head(100))\n",
    "\n",
    "# 绘制原始数据和滤波后的数据比较\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_copy.index, df_copy['value'], 'b-', label='原始数据')\n",
    "plt.plot(df_copy.index, df_copy['sg_filtered'], 'r-', label='滤波后数据')\n",
    "plt.title(f\"{first_file} 数据的Savitzky-Golay滤波\")\n",
    "plt.xlabel('时间')\n",
    "plt.ylabel('数值')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多维数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# 按时间戳模式对数据框进行分组\n",
    "def group_by_timestamp_pattern(dataframes):\n",
    "    # 创建一个字典，按时间戳模式分组\n",
    "    grouped = defaultdict(list)\n",
    "    \n",
    "    # 对每个数据框，提取其时间戳模式（可以使用第一个时间戳的格式作为标识）\n",
    "    for file, df in dataframes.items():\n",
    "        # 获取第一个时间戳作为标识\n",
    "        if not df.empty:\n",
    "            timestamp_pattern = df.index[0].strftime('%Y-%m-%d %H:%M:%S')\n",
    "            grouped[timestamp_pattern].append((file, df))\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "# 合并具有相同时间戳模式的数据框\n",
    "def merge_dataframes_by_timestamp(dataframes):\n",
    "    # 按时间戳模式分组\n",
    "    grouped = group_by_timestamp_pattern(dataframes)\n",
    "    \n",
    "    # 存储合并后的结果\n",
    "    merged_results = {}\n",
    "    \n",
    "    # 对每组进行合并\n",
    "    for pattern, dfs in grouped.items():\n",
    "        # 如果只有一个数据框，则不需要合并\n",
    "        if len(dfs) <= 1:\n",
    "            continue\n",
    "        \n",
    "        # 创建一个空的数据框来存储合并结果\n",
    "        merged_df = pd.DataFrame()\n",
    "        \n",
    "        # 对每个数据框进行合并\n",
    "        for file, df in dfs:\n",
    "            # 将当前数据框的value列重命名为文件名，然后合并\n",
    "            df_renamed = df.rename(columns={'value': file})\n",
    "            \n",
    "            if merged_df.empty:\n",
    "                merged_df = df_renamed\n",
    "            else:\n",
    "                # 使用外连接合并，保留所有时间戳\n",
    "                merged_df = merged_df.join(df_renamed, how='outer')\n",
    "        \n",
    "        # 存储合并结果\n",
    "        merged_results[pattern] = merged_df\n",
    "    \n",
    "    return merged_results\n",
    "\n",
    "# 使用示例（不会执行）：\n",
    "merged_datasets = merge_dataframes_by_timestamp(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import panel as pn\n",
    "import hvplot.pandas\n",
    "\n",
    "# 初始化Panel\n",
    "pn.extension()\n",
    "\n",
    "def align_and_merge_datasets(dataframes):\n",
    "    if not dataframes:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 获取第一个数据集作为基准\n",
    "    first_key = list(dataframes.keys())[0]\n",
    "    reference_df = dataframes[first_key].copy()\n",
    "    target_index = reference_df.index\n",
    "    \n",
    "    # 重命名第一个数据集的列，添加前缀以避免列名冲突\n",
    "    reference_df = reference_df.rename(columns={col: f\"{first_key}_{col}\" for col in reference_df.columns})\n",
    "    \n",
    "    # 初始化合并后的DataFrame\n",
    "    aligned_df = reference_df.copy()\n",
    "    \n",
    "    # 对其他数据集进行对齐\n",
    "    for key in list(dataframes.keys())[1:]:\n",
    "        print(key)\n",
    "        df = dataframes[key].copy()\n",
    "        \n",
    "        # 使用最近邻方法对齐到目标索引\n",
    "        if df.index[0] != target_index[0]:\n",
    "            aligned = df.reindex(target_index, method='nearest')\n",
    "        else:\n",
    "            aligned = df\n",
    "        df_renamed = aligned.rename(columns={'value': key})\n",
    "        # 合并到结果DataFrame\n",
    "        aligned_df = aligned_df.join(df_renamed, how='outer')\n",
    "    \n",
    "    return aligned_df\n",
    "\n",
    "pn.extension('tabulator')\n",
    "# 使用示例\n",
    "alignment_data = align_and_merge_datasets(dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(pn.widgets.Tabulator(alignment_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def slice_time_series(series, method, value):\n",
    "    \"\"\"\n",
    "    根据固定长度或时间周期对时间序列进行切片。\n",
    "\n",
    "    参数:\n",
    "    series (pd.Series 或 pd.DataFrame): 输入的时间序列。对于'period'方法，必须具有DatetimeIndex。\n",
    "    method (str): 切片方法。可选值为 'length' 或 'period'。\n",
    "    value (int 或 str): \n",
    "        - 如果 method 是 'length'，则为一个整数，表示每个切片的固定长度。\n",
    "        - 如果 method 是 'period'，则为一个字符串，表示时间周期（例如 'D' 表示每天，'W' 表示每周，'M' 表示每月）。请参阅 pandas 偏移别名。\n",
    "\n",
    "    返回:\n",
    "    list: 一个包含切片后段（pd.Series 或 pd.DataFrame）的列表。\n",
    "    \"\"\"\n",
    "    slices = []\n",
    "    if method == 'length':\n",
    "        if not isinstance(value, int) or value <= 0:\n",
    "            raise ValueError(\"对于 'length' 方法，value 必须是正整数。\")\n",
    "        \n",
    "        length = value\n",
    "        num_slices = (len(series) + length - 1) // length # 计算需要多少个切片\n",
    "        for i in range(num_slices):\n",
    "            start_index = i * length\n",
    "            end_index = start_index + length\n",
    "            slice_segment = series.iloc[start_index:end_index]\n",
    "            if not slice_segment.empty:\n",
    "                slices.append(slice_segment)\n",
    "                \n",
    "    elif method == 'period':\n",
    "        if not isinstance(series.index, pd.DatetimeIndex):\n",
    "            raise TypeError(\"对于 'period' 方法，序列必须具有 DatetimeIndex。\")\n",
    "        if not isinstance(value, str):\n",
    "             raise ValueError(\"对于 'period' 方法，value 必须是表示频率的字符串（例如 'D', 'W'）。\")\n",
    "            \n",
    "        freq = value\n",
    "        # 使用 Grouper 按指定频率分组\n",
    "        grouped = series.groupby(pd.Grouper(freq=freq))\n",
    "        for _, group_df in grouped:\n",
    "            # 仅添加非空组\n",
    "            if not group_df.empty:\n",
    "                slices.append(group_df)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError(\"无效的方法。请选择 'length' 或 'period'。\")\n",
    "        \n",
    "    return slices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import hvplot.pandas\n",
    "import numpy as np\n",
    "\n",
    "# 初始化 Panel\n",
    "pn.extension()\n",
    "\n",
    "# 创建可视化界面\n",
    "def create_visualization(merged_datasets):\n",
    "    # 创建数据集选择器\n",
    "    dataset_selector = pn.widgets.Select(\n",
    "        name='选择数据集',\n",
    "        options=list(merged_datasets.keys()),\n",
    "        value=list(merged_datasets.keys())[0] if merged_datasets else None\n",
    "    )\n",
    "    \n",
    "    # 创建列选择器\n",
    "    # 首先获取第一个数据集的列作为初始值\n",
    "    initial_columns = []\n",
    "    if merged_datasets and dataset_selector.value in merged_datasets:\n",
    "        initial_columns = list(merged_datasets[dataset_selector.value].columns)\n",
    "    \n",
    "    column_selector = pn.widgets.MultiSelect(\n",
    "        name='选择列',\n",
    "        options=initial_columns,\n",
    "        value=initial_columns[:2] if len(initial_columns) >= 2 else initial_columns,\n",
    "        size=min(10, len(initial_columns))\n",
    "    )\n",
    "    \n",
    "    # 更新列选择器选项的回调函数\n",
    "    def update_column_options(event):\n",
    "        dataset = event.new\n",
    "        if dataset in merged_datasets:\n",
    "            new_columns = list(merged_datasets[dataset].columns)\n",
    "            column_selector.options = new_columns\n",
    "            column_selector.value = new_columns[:2] if len(new_columns) >= 2 else new_columns\n",
    "    \n",
    "    # 监听数据集选择器的变化\n",
    "    dataset_selector.param.watch(update_column_options, 'value')\n",
    "    \n",
    "    # 创建绘图面板\n",
    "    plot_pane = pn.pane.HoloViews(height=500)\n",
    "    \n",
    "    # 创建统计信息面板\n",
    "    stats_pane = pn.pane.DataFrame(width=800)\n",
    "    \n",
    "    # 更新绘图和统计信息的函数\n",
    "    def update_plot_and_stats(event):\n",
    "        dataset = dataset_selector.value\n",
    "        columns = column_selector.value\n",
    "        \n",
    "        if dataset is None or not columns or dataset not in merged_datasets:\n",
    "            plot_pane.object = None\n",
    "            stats_pane.object = None\n",
    "            return\n",
    "        \n",
    "        df = merged_datasets[dataset]\n",
    "        \n",
    "        # 只选择已勾选的列\n",
    "        selected_df = df[columns]\n",
    "        \n",
    "        # 更新图表\n",
    "        plot = selected_df.hvplot.line(\n",
    "            responsive=True,\n",
    "            height=500,\n",
    "            title=f'数据集: {dataset}',\n",
    "            xlabel='时间',\n",
    "            ylabel='数值',\n",
    "            legend='top',\n",
    "            downsample=True,\n",
    "        )\n",
    "        plot_pane.object = plot\n",
    "        \n",
    "        # 更新统计信息\n",
    "        stats = selected_df.describe().T\n",
    "        stats['非空值数'] = selected_df.count()\n",
    "        stats['空值数'] = selected_df.isna().sum()\n",
    "        stats_pane.object = stats\n",
    "    \n",
    "    # 监听列选择器和数据集选择器的变化\n",
    "    column_selector.param.watch(update_plot_and_stats, 'value')\n",
    "    dataset_selector.param.watch(update_plot_and_stats, 'value')\n",
    "    \n",
    "    # 初始更新一次\n",
    "    update_plot_and_stats(None)\n",
    "    \n",
    "    # 组装面板\n",
    "    dashboard = pn.Column(\n",
    "        pn.pane.Markdown(\"## 多维时间序列可视化\"),\n",
    "        pn.Row(\n",
    "                dataset_selector,\n",
    "                column_selector,\n",
    "                pn.pane.Markdown(\"### 统计信息\"),\n",
    "                stats_pane\n",
    "            ),\n",
    "        plot_pane,\n",
    "    )\n",
    "    \n",
    "    return dashboard\n",
    "\n",
    "# 使用示例：\n",
    "viz_dashboard = create_visualization(merged_datasets)\n",
    "viz_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import panel as pn\n",
    "import hvplot.pandas\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from nodes.cluster.TICC.TICC_solver import TICC\n",
    "\n",
    "# 初始化Panel\n",
    "pn.extension()\n",
    "\n",
    "def apply_ticc_to_dataframe(merged_datasets):\n",
    "    # 创建数据集选择器\n",
    "    dataset_selector = pn.widgets.Select(\n",
    "        name='选择数据集',\n",
    "        options=list(merged_datasets.keys()),\n",
    "        value=list(merged_datasets.keys())[0] if merged_datasets else None\n",
    "    )\n",
    "    \n",
    "    # 创建列选择器\n",
    "    initial_columns = []\n",
    "    if merged_datasets and dataset_selector.value in merged_datasets:\n",
    "        initial_columns = list(merged_datasets[dataset_selector.value].columns)\n",
    "    \n",
    "    column_selector = pn.widgets.MultiSelect(\n",
    "        name='选择列',\n",
    "        options=initial_columns,\n",
    "        value=initial_columns[:min(5, len(initial_columns))] if initial_columns else [],\n",
    "        size=min(10, len(initial_columns))\n",
    "    )\n",
    "    \n",
    "    # TICC参数设置\n",
    "    window_size = pn.widgets.IntSlider(name='窗口大小', start=1, end=10, value=5)\n",
    "    number_of_clusters = pn.widgets.IntSlider(name='聚类数', start=2, end=10, value=3)\n",
    "    lambda_param = pn.widgets.FloatSlider(name='Lambda参数', start=0, end=1, value=0.1, step=0.01)\n",
    "    beta = pn.widgets.FloatSlider(name='Beta参数', start=0, end=10, value=5, step=0.1)\n",
    "    maxIters = pn.widgets.IntSlider(name='最大迭代次数', start=10, end=100, value=30, step=5)\n",
    "    \n",
    "    # 更新列选择器选项的回调函数\n",
    "    def update_column_options(event):\n",
    "        dataset = event.new\n",
    "        if dataset in merged_datasets:\n",
    "            new_columns = list(merged_datasets[dataset].columns)\n",
    "            column_selector.options = new_columns\n",
    "            column_selector.value = new_columns[:min(5, len(new_columns))] if new_columns else []\n",
    "    \n",
    "    # 监听数据集选择器的变化\n",
    "    dataset_selector.param.watch(update_column_options, 'value')\n",
    "    \n",
    "    # 创建结果显示区域\n",
    "    result_pane = pn.pane.HoloViews(height=500)\n",
    "    cluster_info_pane = pn.pane.DataFrame(width=800)\n",
    "    \n",
    "    # 运行TICC的按钮\n",
    "    run_button = pn.widgets.Button(name='运行TICC聚类', button_type='primary')\n",
    "    \n",
    "    # TICC运行状态\n",
    "    status = pn.pane.Markdown(\"准备就绪，请选择数据和参数\")\n",
    "    \n",
    "    def run_ticc(event):\n",
    "        dataset = dataset_selector.value\n",
    "        columns = column_selector.value\n",
    "        \n",
    "        if dataset is None or not columns or dataset not in merged_datasets:\n",
    "            status.object = \"请选择数据集和至少一列数据\"\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            status.object = \"正在运行TICC聚类...\"\n",
    "            \n",
    "            # 获取选定的数据\n",
    "            df = merged_datasets[dataset][columns].copy()\n",
    "            \n",
    "            # 处理缺失值并重置索引\n",
    "            df = df.ffill().bfill()\n",
    "            \n",
    "            # 创建TICC实例\n",
    "            ticc = TICC(\n",
    "                window_size=window_size.value,\n",
    "                number_of_clusters=number_of_clusters.value,\n",
    "                lambda_parameter=lambda_param.value,\n",
    "                beta=beta.value,\n",
    "                maxIters=maxIters.value,\n",
    "                threshold=2e-5\n",
    "            )\n",
    "            \n",
    "            # 运行TICC算法\n",
    "            result_df, _ = ticc.fit(df)\n",
    "            \n",
    "            # 检查返回类型\n",
    "            if isinstance(result_df, pd.DataFrame):\n",
    "                # 如果返回DataFrame，直接使用\n",
    "                cluster_assignments = result_df['cluster'].values\n",
    "                # 添加索引\n",
    "                result_df.index = df.index\n",
    "            else:\n",
    "                # 如果返回numpy数组，创建新的DataFrame\n",
    "                cluster_assignments = result_df\n",
    "                result_df = df.copy()\n",
    "                result_df['cluster'] = cluster_assignments\n",
    "            \n",
    "            # 可视化结果 - 按聚类分组\n",
    "            cluster_plots = []\n",
    "            for i in range(number_of_clusters.value):\n",
    "                cluster_data = result_df[result_df['cluster'] == i]\n",
    "                if len(cluster_data) > 0:\n",
    "                    plot = cluster_data.hvplot.line(\n",
    "                        y=columns,\n",
    "                        responsive=True,\n",
    "                        height=300,\n",
    "                        title=f'聚类 {i}',\n",
    "                        xlabel='时间',\n",
    "                        ylabel='数值',\n",
    "                        legend='top'\n",
    "                    )\n",
    "                    cluster_plots.append(plot)\n",
    "            \n",
    "            if cluster_plots:\n",
    "                # 合并所有图表\n",
    "                combined_plot = pn.Column(*cluster_plots)\n",
    "                result_pane.object = combined_plot\n",
    "            else:\n",
    "                result_pane.object = pn.pane.Markdown(\"没有找到有效的聚类结果\")\n",
    "            \n",
    "            # 显示聚类统计信息\n",
    "            unique_clusters = np.unique(cluster_assignments)\n",
    "            cluster_stats = pd.DataFrame({\n",
    "                '聚类标签': unique_clusters,\n",
    "                '点数量': [sum(cluster_assignments == i) for i in unique_clusters],\n",
    "                '占比(%)': [sum(cluster_assignments == i) / len(cluster_assignments) * 100 for i in unique_clusters]\n",
    "            })\n",
    "            \n",
    "            cluster_info_pane.object = cluster_stats\n",
    "            \n",
    "            status.object = \"TICC聚类完成！\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            status.object = f\"错误: {str(e)}\"\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # 绑定按钮事件\n",
    "    run_button.on_click(run_ticc)\n",
    "    \n",
    "    # 组装面板\n",
    "    dashboard = pn.Column(\n",
    "        pn.pane.Markdown(\"## TICC时间序列聚类分析\"),\n",
    "        pn.Row(\n",
    "            pn.Column(\n",
    "                dataset_selector,\n",
    "                column_selector,\n",
    "                pn.pane.Markdown(\"### TICC参数设置\"),\n",
    "                window_size,\n",
    "                number_of_clusters,\n",
    "                lambda_param,\n",
    "                beta,\n",
    "                maxIters,\n",
    "                run_button,\n",
    "                status\n",
    "            ),\n",
    "            pn.Column(\n",
    "                pn.pane.Markdown(\"### 聚类结果\"),\n",
    "                result_pane,\n",
    "                pn.pane.Markdown(\"### 聚类统计\"),\n",
    "                cluster_info_pane\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return dashboard\n",
    "\n",
    "# 使用示例：\n",
    "ticc_dashboard = apply_ticc_to_dataframe(merged_datasets)\n",
    "ticc_dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import panel as pn\n",
    "import hvplot.pandas\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 导入MC2PCA算法\n",
    "sys.path.append(os.path.join(os.getcwd(), 'nodes/cluster'))\n",
    "from MC2PCA import mc2pca_clustering\n",
    "\n",
    "# 初始化Panel\n",
    "pn.extension()\n",
    "\n",
    "def apply_mc2pca_to_dataframe(merged_datasets):\n",
    "    # 创建数据集选择器\n",
    "    dataset_selector = pn.widgets.Select(\n",
    "        name='选择数据集',\n",
    "        options=list(merged_datasets.keys()),\n",
    "        value=list(merged_datasets.keys())[0] if merged_datasets else None\n",
    "    )\n",
    "    \n",
    "    # 创建列选择器\n",
    "    initial_columns = []\n",
    "    if merged_datasets and dataset_selector.value in merged_datasets:\n",
    "        initial_columns = list(merged_datasets[dataset_selector.value].columns)\n",
    "    \n",
    "    column_selector = pn.widgets.MultiSelect(\n",
    "        name='选择列',\n",
    "        options=initial_columns,\n",
    "        value=initial_columns[:min(5, len(initial_columns))] if initial_columns else [],\n",
    "        size=min(10, len(initial_columns))\n",
    "    )\n",
    "    \n",
    "    # MC2PCA参数设置\n",
    "    k_clusters = pn.widgets.IntInput(name='聚类数量(K)', value=2)\n",
    "    ncp = pn.widgets.IntInput(name='主成分数量(ncp)', value=2)\n",
    "    itermax = pn.widgets.IntInput(name='最大迭代次数', value=100)\n",
    "    conv_crit = pn.widgets.FloatInput(name='收敛阈值', value=1e-5)\n",
    "    \n",
    "    # 更新列选择器选项的回调函数\n",
    "    def update_column_options(event):\n",
    "        dataset = event.new\n",
    "        if dataset in merged_datasets:\n",
    "            new_columns = list(merged_datasets[dataset].columns)\n",
    "            column_selector.options = new_columns\n",
    "            column_selector.value = new_columns[:min(5, len(new_columns))] if new_columns else []\n",
    "    \n",
    "    # 监听数据集选择器的变化\n",
    "    dataset_selector.param.watch(update_column_options, 'value')\n",
    "    \n",
    "    # 创建结果显示区域\n",
    "    result_pane = pn.pane.HoloViews(height=500)\n",
    "    cluster_info_pane = pn.pane.DataFrame(width=800)\n",
    "    \n",
    "    # 运行MC2PCA的按钮\n",
    "    run_button = pn.widgets.Button(name='运行MC2PCA聚类', button_type='primary')\n",
    "    \n",
    "    # MC2PCA运行状态\n",
    "    status = pn.pane.Markdown(\"准备就绪，请选择数据和参数\")\n",
    "    \n",
    "    def run_mc2pca(event):\n",
    "        dataset = dataset_selector.value\n",
    "\n",
    "        if dataset is None or dataset not in merged_datasets:\n",
    "            status.object = \"请选择数据集\"\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            status.object = \"正在运行MC2PCA聚类...\"\n",
    "            \n",
    "            # 获取选定的数据\n",
    "            df = merged_datasets[dataset].copy()\n",
    "            \n",
    "            # 处理缺失值\n",
    "            df = df.ffill().bfill()\n",
    "            \n",
    "            # 训练模型并获取聚类结果\n",
    "            result_df = mc2pca_clustering(df, k_clusters.value, ncp.value, itermax.value, conv_crit.value)\n",
    "            \n",
    "            # 可视化结果 - 按聚类分组\n",
    "            cluster_plots = []\n",
    "            for i in range(k_clusters.value):\n",
    "                cluster_data = result_df[result_df['cluster'] == i]\n",
    "                if len(cluster_data) > 0:\n",
    "                    plot = cluster_data.hvplot.line(\n",
    "                        y=columns,\n",
    "                        responsive=True,\n",
    "                        height=300,\n",
    "                        title=f'聚类 {i}',\n",
    "                        xlabel='时间',\n",
    "                        ylabel='数值',\n",
    "                        legend='top'\n",
    "                    )\n",
    "                    cluster_plots.append(plot)\n",
    "            \n",
    "            if cluster_plots:\n",
    "                # 合并所有图表\n",
    "                combined_plot = pn.Column(*cluster_plots)\n",
    "                result_pane.object = combined_plot\n",
    "            else:\n",
    "                result_pane.object = pn.pane.Markdown(\"没有找到有效的聚类结果\")\n",
    "            \n",
    "            # 显示聚类统计信息\n",
    "            unique_clusters = np.unique(result_df['cluster'])\n",
    "            cluster_stats = pd.DataFrame({\n",
    "                '聚类标签': unique_clusters,\n",
    "                '点数量': [sum(result_df['cluster'] == i) for i in unique_clusters],\n",
    "                '占比(%)': [sum(result_df['cluster'] == i) / len(result_df['cluster']) * 100 for i in unique_clusters]\n",
    "            })\n",
    "            \n",
    "            cluster_info_pane.object = cluster_stats\n",
    "            \n",
    "            status.object = \"MC2PCA聚类完成！\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            status.object = f\"错误: {str(e)}\"\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # 绑定按钮事件\n",
    "    run_button.on_click(run_mc2pca)\n",
    "    \n",
    "    # 组装面板\n",
    "    dashboard = pn.Column(\n",
    "        pn.pane.Markdown(\"## MC2PCA时间序列聚类分析\"),\n",
    "        pn.Row(\n",
    "            pn.Column(\n",
    "                dataset_selector,\n",
    "                column_selector,\n",
    "                pn.pane.Markdown(\"### MC2PCA参数设置\"),\n",
    "                k_clusters,\n",
    "                ncp,\n",
    "                itermax,\n",
    "                conv_crit,\n",
    "                run_button,\n",
    "                status\n",
    "            ),\n",
    "            pn.Column(\n",
    "                pn.pane.Markdown(\"### 聚类结果\"),\n",
    "                result_pane,\n",
    "                pn.pane.Markdown(\"### 聚类统计\"),\n",
    "                cluster_info_pane\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return dashboard\n",
    "\n",
    "# 使用示例：\n",
    "mc2pca_dashboard = apply_mc2pca_to_dataframe(merged_datasets)\n",
    "mc2pca_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def slice_dataframe(df, by='length', value=100):\n",
    "    \"\"\"\n",
    "    将DataFrame按指定长度或时长切片，返回DataFrame列表。\n",
    "\n",
    "    参数:\n",
    "    df: 输入的DataFrame，索引可以为整数或DatetimeIndex\n",
    "    by: 'length'（按行数）或 'timedelta'（按时长）\n",
    "    value: \n",
    "        - 当by='length'时，value为每个切片的行数（int）\n",
    "        - 当by='timedelta'时，value为pandas可识别的时间长度字符串（如'10T', '1H'）\n",
    "\n",
    "    返回:\n",
    "    df_list: 切片后的DataFrame列表\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    if by == 'length':\n",
    "        n = int(value)\n",
    "        for i in range(0, len(df), n):\n",
    "            df_list.append(df.iloc[i:i+n])\n",
    "    elif by == 'timedelta':\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            raise ValueError(\"索引必须为DatetimeIndex才能按时长切片\")\n",
    "        value = pd.to_timedelta(value)\n",
    "        start = df.index[0]\n",
    "        end = df.index[-1]\n",
    "        current = start\n",
    "        while current < end:\n",
    "            next_time = current + value\n",
    "            df_slice = df[(df.index >= current) & (df.index < next_time)]\n",
    "            if not df_slice.empty:\n",
    "                df_list.append(df_slice)\n",
    "            current = next_time\n",
    "    else:\n",
    "        raise ValueError(\"by参数必须为'length'或'timedelta'\")\n",
    "    return df_list\n",
    "\n",
    "# # 示例用法\n",
    "# df_slices = slice_dataframe(df, by='length', value=200)\n",
    "# df_slices = slice_dataframe(df, by='timedelta', value='30T')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
